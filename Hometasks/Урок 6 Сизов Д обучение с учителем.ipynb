{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеки pandas и numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "X=pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "# X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(boston.target, columns=['Price'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484943"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train,y_train.values[:,0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_frst_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749965273218174"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_frst_pred) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* Задание 3\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 13 artists>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(boston.feature_names, model.feature_importances_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Задание 4\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "\n",
    "Просмотрите первые 10 строк датафрейма df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=df.columns\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создайте датафрейм X из датафрейма df, исключив столбец Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Class', axis=1)\n",
    "# X.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создайте объект Series под названием y из столбца Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.Series(df['Class'])\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[{\n",
    "    'n_estimators':[10,15],\n",
    "    'max_features':np.arange(3,5),\n",
    "    'max_depth':np.arange(4,7)\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf=GridSearchCV(estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=100, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [10, 15], 'max_features': array([3, 4]), 'max_depth': array([4, 5, 6])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументовмассивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_pr=clf.predict_proba(X_test)\n",
    "pr_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba=pr_pr[:,1]\n",
    "y_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037156"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Дополнительные задания:\n",
    "1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.\n",
    "2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.4). Сколько классов содержит целевая переменная датасета? Выве\n",
    "дите названия классов.\n",
    "5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X.\n",
    "6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.\n",
    "8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список).\n",
    "10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
